{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72ee6e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "115ac672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_TOKEN']=os.getenv(\"HF_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "062b8ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\AGENTICAIPROJ\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab4af00d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.033388182520866394,\n",
       " 0.03453972190618515,\n",
       " 0.059474531561136246,\n",
       " 0.05928609147667885,\n",
       " -0.0635354220867157,\n",
       " -0.06819586455821991,\n",
       " 0.08823323994874954,\n",
       " 0.03444080427289009,\n",
       " -0.03278516232967377,\n",
       " -0.015814989805221558,\n",
       " 0.02098178118467331,\n",
       " -0.01834029331803322,\n",
       " -0.03983215242624283,\n",
       " -0.0804707482457161,\n",
       " -0.014469144865870476,\n",
       " 0.0332648828625679,\n",
       " 0.014259284362196922,\n",
       " -0.03404996916651726,\n",
       " -0.142915740609169,\n",
       " -0.023083344101905823,\n",
       " -0.021380102261900902,\n",
       " 0.002633501309901476,\n",
       " -0.047292742878198624,\n",
       " -0.010752756148576736,\n",
       " -0.06866798549890518,\n",
       " 0.031125057488679886,\n",
       " 0.0759458914399147,\n",
       " 0.0011283254716545343,\n",
       " 0.011631987057626247,\n",
       " -0.03603919595479965,\n",
       " 0.04483763128519058,\n",
       " 0.018390750512480736,\n",
       " 0.12672801315784454,\n",
       " -0.0013597895158454776,\n",
       " 0.008206663653254509,\n",
       " 0.06909968703985214,\n",
       " -0.08076353371143341,\n",
       " -0.05841314047574997,\n",
       " 0.053754497319459915,\n",
       " 0.026227595284581184,\n",
       " -0.006828607991337776,\n",
       " -0.056358352303504944,\n",
       " 0.0032930178567767143,\n",
       " -0.0725017860531807,\n",
       " 0.06960923224687576,\n",
       " 0.03167439252138138,\n",
       " -0.012384781613945961,\n",
       " 0.023199191316962242,\n",
       " 0.08131051808595657,\n",
       " 0.0002782986266538501,\n",
       " -0.12659239768981934,\n",
       " -0.04998627305030823,\n",
       " -0.03565250337123871,\n",
       " 0.048560675233602524,\n",
       " 0.09733071178197861,\n",
       " 0.062244169414043427,\n",
       " -0.03750475123524666,\n",
       " 0.008118408732116222,\n",
       " 0.02765134535729885,\n",
       " -0.04321667551994324,\n",
       " 0.016248490661382675,\n",
       " 0.002286782255396247,\n",
       " 0.003097104374319315,\n",
       " -0.015322064980864525,\n",
       " 0.03742995485663414,\n",
       " -0.010506645776331425,\n",
       " -0.05321492627263069,\n",
       " -0.03969471529126167,\n",
       " -0.05287756025791168,\n",
       " -0.030448202043771744,\n",
       " -0.011697022244334221,\n",
       " 0.07245178520679474,\n",
       " -0.07213431596755981,\n",
       " 0.03910218924283981,\n",
       " -0.03716369718313217,\n",
       " 0.026422226801514626,\n",
       " 0.026734257116913795,\n",
       " -0.03114689700305462,\n",
       " 0.06340930610895157,\n",
       " -0.01694675162434578,\n",
       " 0.006343594286590815,\n",
       " -0.025483090430498123,\n",
       " -0.01599896140396595,\n",
       " 0.01468465756624937,\n",
       " -0.04103191941976547,\n",
       " 0.056689392775297165,\n",
       " 0.051890779286623,\n",
       " 0.012766438536345959,\n",
       " 0.010396641679108143,\n",
       " 0.03603467345237732,\n",
       " -0.07487247884273529,\n",
       " 0.022285493090748787,\n",
       " 0.05366939678788185,\n",
       " 0.021017177030444145,\n",
       " 0.010703198611736298,\n",
       " 0.011209441348910332,\n",
       " 0.022165238857269287,\n",
       " -0.03350187838077545,\n",
       " -0.13790263235569,\n",
       " 0.17661647498607635,\n",
       " 0.032913580536842346,\n",
       " 0.07648536562919617,\n",
       " -0.05645773187279701,\n",
       " 0.03820188716053963,\n",
       " -0.05886794999241829,\n",
       " 0.016183646395802498,\n",
       " -0.0029855123721063137,\n",
       " 0.008209950290620327,\n",
       " 0.026603657752275467,\n",
       " 0.03410134091973305,\n",
       " -0.0033712659496814013,\n",
       " -0.04683651030063629,\n",
       " 0.029342347756028175,\n",
       " -0.01816543936729431,\n",
       " 0.09393950551748276,\n",
       " 0.016673743724822998,\n",
       " -0.01623217761516571,\n",
       " 0.071003258228302,\n",
       " 0.041898347437381744,\n",
       " -0.012874962761998177,\n",
       " 0.02733326517045498,\n",
       " -0.03769178315997124,\n",
       " -0.01056569255888462,\n",
       " 0.08810011297464371,\n",
       " 0.03338450565934181,\n",
       " -0.0023000268265604973,\n",
       " -0.020081715658307076,\n",
       " -3.4389641919702815e-33,\n",
       " 0.00388541747815907,\n",
       " -0.04569804668426514,\n",
       " 0.03672381490468979,\n",
       " 0.10973253101110458,\n",
       " 0.0052942801266908646,\n",
       " -0.03384026512503624,\n",
       " -0.05718807131052017,\n",
       " -0.0309864804148674,\n",
       " 0.02820853516459465,\n",
       " 0.014682847075164318,\n",
       " -0.005613868124783039,\n",
       " 0.02814442850649357,\n",
       " -0.06591308116912842,\n",
       " 0.016082217916846275,\n",
       " 0.048449140042066574,\n",
       " 0.07509640604257584,\n",
       " -0.004293232224881649,\n",
       " 0.026304595172405243,\n",
       " -0.028514456003904343,\n",
       " 0.02287396416068077,\n",
       " -0.052803438156843185,\n",
       " -0.06066504865884781,\n",
       " 0.01952851377427578,\n",
       " 0.0541018582880497,\n",
       " 0.02175351046025753,\n",
       " -0.025309881195425987,\n",
       " 0.031614743173122406,\n",
       " -0.12111617624759674,\n",
       " 0.049283310770988464,\n",
       " 0.0027340934611856937,\n",
       " -0.03895929083228111,\n",
       " -0.02350742556154728,\n",
       " 0.010390667244791985,\n",
       " 0.026675894856452942,\n",
       " -0.020386094227433205,\n",
       " 0.013104453682899475,\n",
       " 0.012831252999603748,\n",
       " -0.027721215039491653,\n",
       " -0.07600448280572891,\n",
       " 0.039699096232652664,\n",
       " -0.06335609406232834,\n",
       " 0.06014362350106239,\n",
       " 0.052485134452581406,\n",
       " 0.008374596014618874,\n",
       " 0.015201508067548275,\n",
       " -0.018722591921687126,\n",
       " 0.01212178822606802,\n",
       " -0.01437518559396267,\n",
       " 0.03359777852892876,\n",
       " -0.01308045070618391,\n",
       " -0.06113581359386444,\n",
       " 0.029406405985355377,\n",
       " -0.09374044835567474,\n",
       " -0.002057659672573209,\n",
       " 0.02402631565928459,\n",
       " -0.04306025058031082,\n",
       " -0.03385310620069504,\n",
       " -0.0036304595414549112,\n",
       " 0.00576019985601306,\n",
       " 0.019234400242567062,\n",
       " 0.024349475279450417,\n",
       " 0.0710911825299263,\n",
       " -0.044835008680820465,\n",
       " 0.07316724210977554,\n",
       " -0.08264458179473877,\n",
       " 0.005427949130535126,\n",
       " 0.023218736052513123,\n",
       " 0.060967545956373215,\n",
       " 0.09460736811161041,\n",
       " -0.014135177247226238,\n",
       " -0.041771091520786285,\n",
       " -0.027401844039559364,\n",
       " 0.03853406384587288,\n",
       " -0.0073499674908816814,\n",
       " -0.007266188506036997,\n",
       " 0.048032645136117935,\n",
       " -0.01142663974314928,\n",
       " -0.06901125609874725,\n",
       " 0.0371512770652771,\n",
       " -0.06476707756519318,\n",
       " -0.06643088161945343,\n",
       " -0.0011766892857849598,\n",
       " -0.02179594896733761,\n",
       " -0.007523776963353157,\n",
       " 0.06725426018238068,\n",
       " 0.00809473730623722,\n",
       " -0.03811290115118027,\n",
       " -0.08759457617998123,\n",
       " 0.030362332239747047,\n",
       " -0.04203790798783302,\n",
       " -0.06107683852314949,\n",
       " 0.012958238832652569,\n",
       " 0.005050858482718468,\n",
       " 0.018419789150357246,\n",
       " -0.12826375663280487,\n",
       " 2.624874844624337e-33,\n",
       " 0.08888931572437286,\n",
       " 0.032136209309101105,\n",
       " -0.10708094388246536,\n",
       " -0.016275133937597275,\n",
       " -0.04150315746665001,\n",
       " 0.002086902502924204,\n",
       " -0.06067203730344772,\n",
       " 0.12048251181840897,\n",
       " -0.08354715257883072,\n",
       " 0.050116825848817825,\n",
       " 0.0011806325055658817,\n",
       " -0.05077023431658745,\n",
       " 0.05996881425380707,\n",
       " 0.054858800023794174,\n",
       " 0.06972206383943558,\n",
       " 0.004157152492552996,\n",
       " 0.12240331619977951,\n",
       " 0.038177911192178726,\n",
       " -0.018991993740200996,\n",
       " 0.012684158980846405,\n",
       " -0.032571226358413696,\n",
       " 0.026601171121001244,\n",
       " -0.05980314686894417,\n",
       " -0.024400899186730385,\n",
       " -0.016547149047255516,\n",
       " 0.020274391397833824,\n",
       " -0.0235400702804327,\n",
       " 0.08794981986284256,\n",
       " -0.09462466835975647,\n",
       " -0.05664946138858795,\n",
       " 0.07793813198804855,\n",
       " -0.014540212228894234,\n",
       " -0.04598593711853027,\n",
       " 0.03597735986113548,\n",
       " 0.017227422446012497,\n",
       " 0.10854928195476532,\n",
       " 0.0239954125136137,\n",
       " -0.09443830698728561,\n",
       " 0.021734826266765594,\n",
       " -0.03514188528060913,\n",
       " -0.015563013032078743,\n",
       " -0.00905606895685196,\n",
       " -0.026420556008815765,\n",
       " 0.09819947928190231,\n",
       " -0.05173283815383911,\n",
       " -0.05118061229586601,\n",
       " -0.04413073882460594,\n",
       " 0.060778893530368805,\n",
       " -0.01092182844877243,\n",
       " -0.0016202690312638879,\n",
       " -0.12291137129068375,\n",
       " -0.08137031644582748,\n",
       " -0.02304576151072979,\n",
       " -0.050796691328287125,\n",
       " -0.1166769489645958,\n",
       " 0.025221578776836395,\n",
       " -0.019859880208969116,\n",
       " 0.049684543162584305,\n",
       " -0.013690224848687649,\n",
       " 0.004341150168329477,\n",
       " -0.014368350617587566,\n",
       " 0.04770710691809654,\n",
       " 0.03718509152531624,\n",
       " 0.022829849272966385,\n",
       " -0.04654858633875847,\n",
       " 0.0693684071302414,\n",
       " -0.02132509835064411,\n",
       " 0.02957007847726345,\n",
       " 0.0009863259037956595,\n",
       " -0.033218443393707275,\n",
       " 0.04180170223116875,\n",
       " -0.005182818975299597,\n",
       " -0.020640283823013306,\n",
       " 0.048608046025037766,\n",
       " -0.04133274778723717,\n",
       " -0.005364623386412859,\n",
       " -0.021894976496696472,\n",
       " 0.021270232275128365,\n",
       " 0.01846093125641346,\n",
       " -0.036591045558452606,\n",
       " -0.057284705340862274,\n",
       " -0.0034459782764315605,\n",
       " -0.04625880345702171,\n",
       " 0.05134569853544235,\n",
       " 0.025934085249900818,\n",
       " 0.03859257698059082,\n",
       " 0.06607185304164886,\n",
       " -0.017302462831139565,\n",
       " -0.01059807650744915,\n",
       " 0.02265203557908535,\n",
       " 0.036723792552948,\n",
       " 0.03584650158882141,\n",
       " 0.012036577798426151,\n",
       " 0.031785935163497925,\n",
       " -0.12105195224285126,\n",
       " -1.5130833475041072e-08,\n",
       " 0.006866040639579296,\n",
       " -0.027710257098078728,\n",
       " 0.08934704959392548,\n",
       " 0.07790020108222961,\n",
       " 0.06404799222946167,\n",
       " 0.03166109696030617,\n",
       " -0.07114408910274506,\n",
       " -0.043268363922834396,\n",
       " -0.03240786865353584,\n",
       " -0.02145577408373356,\n",
       " -0.00830535776913166,\n",
       " 0.0380602702498436,\n",
       " -0.0001136258797487244,\n",
       " 0.012233691290020943,\n",
       " 0.12013918161392212,\n",
       " 0.030236663296818733,\n",
       " -0.05191421881318092,\n",
       " -0.011444020085036755,\n",
       " -0.047843098640441895,\n",
       " -0.07834552228450775,\n",
       " 0.03221028298139572,\n",
       " -0.02586168795824051,\n",
       " -0.0020645149052143097,\n",
       " -0.029230767861008644,\n",
       " -0.01997465081512928,\n",
       " -0.03496573865413666,\n",
       " -0.014112595468759537,\n",
       " 0.03993980586528778,\n",
       " -0.06896215677261353,\n",
       " 0.05589042976498604,\n",
       " -0.012570559047162533,\n",
       " 0.1819690614938736,\n",
       " -0.012776440940797329,\n",
       " -0.001151281176134944,\n",
       " 0.028124773874878883,\n",
       " 0.011322916485369205,\n",
       " 0.04628046602010727,\n",
       " 0.016169793903827667,\n",
       " 0.02629891224205494,\n",
       " -0.05404873937368393,\n",
       " -0.026807203888893127,\n",
       " 0.06764835864305496,\n",
       " 0.01065937802195549,\n",
       " -0.1292618066072464,\n",
       " 0.06938319653272629,\n",
       " 0.030720505863428116,\n",
       " 0.03887757286429405,\n",
       " -0.14078202843666077,\n",
       " 0.05191187933087349,\n",
       " -0.06790675222873688,\n",
       " -0.02985665202140808,\n",
       " 0.017362026497721672,\n",
       " 0.08236218988895416,\n",
       " 0.11180814355611801,\n",
       " 0.09893383085727692,\n",
       " 0.05719546228647232,\n",
       " 0.015903133898973465,\n",
       " -0.04091331735253334,\n",
       " -0.012436377815902233,\n",
       " 0.02024916745722294,\n",
       " 0.06743752211332321,\n",
       " 0.03933350741863251,\n",
       " 0.05208093672990799,\n",
       " -0.019405053928494453]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.embed_query(\"hello AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8b8b1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings.embed_query(\"hello AI\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dda6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecc9cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pinecone_api_key=os.getenv(\"PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a759f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc=Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87c0bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import ServerlessSpec\n",
    "#Serverless: Server will be Managed by the cloud provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fabd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name=\"agenticbatch2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7517b30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.has_index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014f75eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a index\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=384,\n",
    "    metric=\"cosine\",\n",
    "    spec=ServerlessSpec(cloud=\"aws\",region=\"us-east-1\")    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c65a597",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the index\n",
    "index=pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aa626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7412f289",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store=PineconeVectorStore(index=index,embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f6033c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vector_store.similarity_search(\"what is a langchain?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac6e71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28255123",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "document_1 = Document(\n",
    "    page_content=\"I had chocolate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet\"},#additional info\n",
    ")\n",
    "\n",
    "document_2 = Document(\n",
    "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_3 = Document(\n",
    "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_4 = Document(\n",
    "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_5 = Document(\n",
    "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_6 = Document(\n",
    "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    ")\n",
    "\n",
    "document_7 = Document(\n",
    "    page_content=\"The top 10 soccer players in the world right now.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    ")\n",
    "\n",
    "document_8 = Document(\n",
    "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_9 = Document(\n",
    "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_10 = Document(\n",
    "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59af54c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    document_1,\n",
    "    document_2,\n",
    "    document_3,\n",
    "    document_4,\n",
    "    document_5,\n",
    "    document_6,\n",
    "    document_7,\n",
    "    document_8,\n",
    "    document_9,\n",
    "    document_10,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2065646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c92235",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80caa055",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(len(documents)):\n",
    "    print(_)\n",
    "    print(str(uuid4()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eefdad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#universal indentification number\n",
    "uuids = [str(uuid4()) for _ in range(len(documents))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a03838",
   "metadata": {},
   "outputs": [],
   "source": [
    "uuids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15742510",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.add_documents(documents=documents, ids=uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c50d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vector_store.similarity_search(\"what langchain provides to us?\",k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed64abc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6a83d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vector_store.similarity_search(\"what langchain provides to us?\",filter={\"source\": \"tweet\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bc44e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecaccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vector_store.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"score_threshold\": 0.7} #hyperparameter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afe12b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.invoke(\"langchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90130ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"o1-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15a9631",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dbbaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pprint.pprint(prompt.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12051897",
   "metadata": {},
   "source": [
    "[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1c482d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755c912f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=PromptTemplate(\n",
    "    template=\"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"\"\",\n",
    "    input_variables=['context', 'question']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1128b4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869034b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt.invoke({\"question\":\"what is a langchain?\",\"context\":\"langchain is very super framework for LLM.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40891f9c",
   "metadata": {},
   "source": [
    "StringPromptValue(text=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: what is a langchain? \\nContext: langchain is very super framework for LLM. \\nAnswer:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4082ad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcc390d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c433e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d599f565",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain.invoke(\"what is llama model?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
